{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a39f84f-74fe-48db-98e0-0cd26e4e103f",
   "metadata": {},
   "source": [
    "# Extract Transform Load\n",
    "In this notebook, we extract data from the praise worksheet, transform it into suitable, clean data, and load it into the outputs directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35d35c8-fa43-4022-9079-89b29cc10d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849607d6-9d9a-4dc4-853c-fca90c45bf2c",
   "metadata": {},
   "source": [
    "## Total Hours Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1e6558-d5da-4c95-9a5f-a0344fd3943e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Impact Hours</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Handle, Impact Hours, Unnamed: 2, Unnamed: 3]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hours = pd.read_excel(\"data/TEC Praise Quantification.xlsx\", sheet_name=\"Total Impact Hours so far\", engine='openpyxl', header=1, index_col=0, usecols=\"A:D\").dropna(thresh=2).reset_index()\n",
    "total_hours.to_csv('outputs/total_hours.csv', index=False)\n",
    "total_hours.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81b5b4-35f7-404c-9c0f-afbb3297c8b0",
   "metadata": {},
   "source": [
    "## Praise Dataset\n",
    "We consider three batches of praise. Batch one is October 2020, and December2020-May2021. Batch two is prior to December 2020 (other than October). Batch three is after May 7th 2021. Batch one is the original batch that all analysis was performed on. Chronologically, prior to Batch one (batch two) is the early days of praise, and batch 3 is praise that started after the initial praise analysis began."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664246b-6223-4271-abfa-ace7b902cfe9",
   "metadata": {},
   "source": [
    "#### Batch One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7e4e9c-c66c-4f13-92a4-d8d2e57a1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [\n",
    "    \"#17 May 7\",\n",
    "    \"#16 Apr 24\",\n",
    "    \"#15 Apr 9\",\n",
    "    \"#14 Mar 26\",\n",
    "    \"#13 Mar 12\",\n",
    "    \"#12 Feb 26\",\n",
    "    \"#11 Feb 12\",\n",
    "    \"#10 Jan 29\",\n",
    "    \"#9 Jan 15\", \n",
    "    \"#8 Jan 1\",\n",
    "    \"#7 Dec 18\",\n",
    "    \"#6 Dec 4\",\n",
    "    \"#2 Oct 9\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed32d96-c145-4f57-a84f-bdb8d89b0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_period_from_sheet(period: str, batch: str) -> pd.DataFrame:\n",
    "        # Load the data\n",
    "        df = pd.read_excel('data/TEC Praise Quantification.xlsx', skiprows=2, sheet_name=period,engine='openpyxl', usecols=\"A:M\")\n",
    "        \n",
    "        # Add a period column\n",
    "        df['period'] = period\n",
    "        df['batch'] = batch\n",
    "        \n",
    "        # Remove the validator normalization as it is confusing and unecessary for analysis\n",
    "        df.columns = list(df.columns[:6]) + ['v1 norm', 'v2 norm', 'v3 norm'] + list(df.columns[9:])\n",
    "        df = df.dropna(thresh=8).drop(['v1 norm', 'v2 norm', 'v3 norm'], axis=1)\n",
    "        \n",
    "        # Return the loaded df\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac21b5fa-747b-46ac-bb5b-b4ef7f0e3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate data\n",
    "data = pd.concat([read_period_from_sheet(p, batch='Batch 1') for p in periods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc35ed3-4743-41fe-b8f3-375e56a1ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these duplicate columns and drop the lesser named one.\n",
    "df = data.copy()\n",
    "# To\n",
    "df['To'] = df['To'].combine_first(df['To.1']).combine_first(df['Unnamed: 12'])\n",
    "df = df.drop(['To.1', 'Unnamed: 12'], axis=1)\n",
    "\n",
    "# IH Per Praise\n",
    "df['IH per Praise'] = df['IH per Praise'].combine_first(df['Cred per Praise'])\n",
    "df = df.drop('Cred per Praise', axis=1)\n",
    "\n",
    "# IH Per Person Per Period\n",
    "df['IH per person'] = df['IH per person'].combine_first(df['Cred per person'])\n",
    "df = df.drop('Cred per person', axis=1)\n",
    "\n",
    "# Rename The Institution Column\n",
    "df = df.rename({'Unnamed: 3':'Institution'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f59fbd-36b6-4aa0-ab37-a413c05050a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>From</th>\n",
       "      <th>Reason for dishing</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Date</th>\n",
       "      <th>Room</th>\n",
       "      <th>Avg %</th>\n",
       "      <th>IH per Praise</th>\n",
       "      <th>IH per person</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>batch</th>\n",
       "      <th>Cred per Praise</th>\n",
       "      <th>Cred per person</th>\n",
       "      <th>To.1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#10 Jan 29</th>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>573</td>\n",
       "      <td>569</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#11 Feb 12</th>\n",
       "      <td>463</td>\n",
       "      <td>463</td>\n",
       "      <td>463</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>463</td>\n",
       "      <td>454</td>\n",
       "      <td>463</td>\n",
       "      <td>400</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#12 Feb 26</th>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>646</td>\n",
       "      <td>646</td>\n",
       "      <td>646</td>\n",
       "      <td>662</td>\n",
       "      <td>657</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#13 Mar 12</th>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>624</td>\n",
       "      <td>624</td>\n",
       "      <td>624</td>\n",
       "      <td>651</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#14 Mar 26</th>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>774</td>\n",
       "      <td>774</td>\n",
       "      <td>774</td>\n",
       "      <td>804</td>\n",
       "      <td>797</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#15 Apr 9</th>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#16 Apr 24</th>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>908</td>\n",
       "      <td>905</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#17 May 7</th>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "      <td>974</td>\n",
       "      <td>971</td>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#2 Oct 9</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#6 Dec 4</th>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#7 Dec 18</th>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>478</td>\n",
       "      <td>476</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#8 Jan 1</th>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "      <td>357</td>\n",
       "      <td>355</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#9 Jan 15</th>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>587</td>\n",
       "      <td>587</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             To  From  Reason for dishing  Unnamed: 3  Date  Room  Avg %  \\\n",
       "period                                                                     \n",
       "#10 Jan 29  575   575                 575         552   552   552    573   \n",
       "#11 Feb 12  463   463                 463         438   438   438    463   \n",
       "#12 Feb 26  672   672                 672         646   646   646    662   \n",
       "#13 Mar 12  651   651                 651         624   624   624    651   \n",
       "#14 Mar 26  804   804                 804         774   774   774    804   \n",
       "#15 Apr 9   963   963                 963         932   932   932    963   \n",
       "#16 Apr 24  908   908                 908         875   875   875    908   \n",
       "#17 May 7   974   974                 974         940   940   940    974   \n",
       "#2 Oct 9    124   124                 124         124   124   124    124   \n",
       "#6 Dec 4    509   509                 509         490   490   490    509   \n",
       "#7 Dec 18   479   479                 479         457   457   457    478   \n",
       "#8 Jan 1    358   358                 358         336   336   336    357   \n",
       "#9 Jan 15   589   589                 589         566   566   566    587   \n",
       "\n",
       "            IH per Praise  IH per person  Unnamed: 12  batch  Cred per Praise  \\\n",
       "period                                                                          \n",
       "#10 Jan 29            569            575          575    575                0   \n",
       "#11 Feb 12            454            463          400    463                0   \n",
       "#12 Feb 26            657            672          672    672                0   \n",
       "#13 Mar 12            649            651          651    651                0   \n",
       "#14 Mar 26            797            804          804    804                0   \n",
       "#15 Apr 9             963            963          963    963                0   \n",
       "#16 Apr 24            905            908          908    908                0   \n",
       "#17 May 7             971            974          974    974                0   \n",
       "#2 Oct 9                0              0            0    124              124   \n",
       "#6 Dec 4                0              0          509    509              509   \n",
       "#7 Dec 18             476            479          479    479                0   \n",
       "#8 Jan 1              355            358          358    358                0   \n",
       "#9 Jan 15             587            589          589    589                0   \n",
       "\n",
       "            Cred per person  To.1  \n",
       "period                             \n",
       "#10 Jan 29                0     0  \n",
       "#11 Feb 12                0     0  \n",
       "#12 Feb 26                0     0  \n",
       "#13 Mar 12                0     0  \n",
       "#14 Mar 26                0     0  \n",
       "#15 Apr 9                 0     0  \n",
       "#16 Apr 24                0     0  \n",
       "#17 May 7                 0     0  \n",
       "#2 Oct 9                124   124  \n",
       "#6 Dec 4                509     0  \n",
       "#7 Dec 18                 0     0  \n",
       "#8 Jan 1                  0     0  \n",
       "#9 Jan 15                 0     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('period').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add775d-72a3-4af1-beab-da6942402ca2",
   "metadata": {},
   "source": [
    "#### Batch Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9cd7a0f-01aa-42d1-b5fd-aeb43b203c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>From</th>\n",
       "      <th>Reason for dishing</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Date</th>\n",
       "      <th>Room</th>\n",
       "      <th>Avg %</th>\n",
       "      <th>IH per Praise</th>\n",
       "      <th>IH per person</th>\n",
       "      <th>period</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VitorMarthendal</td>\n",
       "      <td>iviangita#3204</td>\n",
       "      <td>for pushing to get the Hatch Dashboard out</td>\n",
       "      <td>Token Engineering Commons</td>\n",
       "      <td>May-07-2021</td>\n",
       "      <td>🙏praise</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>26.540405</td>\n",
       "      <td>7.559265</td>\n",
       "      <td>#17 May 7</td>\n",
       "      <td>Batch 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                To            From  \\\n",
       "0  VitorMarthendal  iviangita#3204   \n",
       "\n",
       "                            Reason for dishing                Institution  \\\n",
       "0  for pushing to get the Hatch Dashboard out   Token Engineering Commons   \n",
       "\n",
       "          Date     Room     Avg %  IH per Praise  IH per person     period  \\\n",
       "0  May-07-2021  🙏praise  0.022117      26.540405       7.559265  #17 May 7   \n",
       "\n",
       "     batch  \n",
       "0  Batch 1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c53be68-b6a3-4f33-b423-c9d256b2b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [\n",
    "    \"#5 Nov 20\", \n",
    "    \"#4 Nov 6\", \n",
    "    \"#3 Oct 23\", \n",
    "    \"#1 Sept 24\", \n",
    "    \"#0 Sept 7 (historic)\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b83fe8-fd71-4835-8c57-de2b6f6a4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([read_period_from_sheet(p, batch='Batch 2') for p in periods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200493db-3b75-4d39-8b19-0d8bd7bda20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these duplicate columns and drop the lesser named one.\n",
    "df2 = data2.copy()\n",
    "# To\n",
    "df2['To'] = df2['To'].combine_first(df2['To.1'])\n",
    "df2 = df2.drop(['To.1'], axis=1)\n",
    "\n",
    "# IH Per Praise\n",
    "df2 = df2.rename({'Cred per Praise':'IH per Praise'}, axis=1)\n",
    "\n",
    "# IH Per Person Per Period\n",
    "df2 = df2.rename({'Cred per person':'IH per person'}, axis=1)\n",
    "\n",
    "# Rename The Institution Column\n",
    "df2 = df2.rename({'Unnamed: 3':'Institution'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60687e-0fde-4ee4-8687-6efbd590ce0d",
   "metadata": {},
   "source": [
    "#### Batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6322da72-3a51-405d-9253-8d85ab73651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [\n",
    "    \"#18 May 21\",\n",
    "    \"#19 Jun 4\",\n",
    "    \"#20 Jun 18\",\n",
    "    \"#21 July 1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef479abd-5b83-4350-a490-b6fb60de1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.concat([read_period_from_sheet(p, batch='Batch 3') for p in periods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8db1c589-67d2-45ab-8c1a-34030d685c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these duplicate columns and drop the lesser named one.\n",
    "df3 = data3.copy()\n",
    "# To\n",
    "df3['To'] = df3['To'].combine_first(df3['Unnamed: 12'])\n",
    "df3 = df3.drop(['Unnamed: 12'], axis=1)\n",
    "\n",
    "# Rename The Institution Column\n",
    "df3 = df3.rename({'Unnamed: 3':'Institution'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da23a2-b449-49f3-bcba-c2011ce32f23",
   "metadata": {},
   "source": [
    "### Concatenate Praise Batches into Praise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aea094ef-3b0e-49eb-baf9-6ffce7fffaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df, df2, df3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d8e72-a52a-4eeb-babd-535e584731d0",
   "metadata": {},
   "source": [
    "### Resolving Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9ae45d7-5d15-43b8-9d0e-7d4dde9dc971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are still missing 12 names\n"
     ]
    }
   ],
   "source": [
    "names_df = pd.read_excel('data/TEC Praise Quantification.xlsx',sheet_name=\"DO NOT TOUCH Imported\",engine='openpyxl', usecols=\"A:D\")\n",
    "\n",
    "#### We create a dictionary that matches each non-null entry in the spreadsheet to its \"IH & CSTK Handle\"\n",
    "source_cols = names_df.columns\n",
    "names_dict = {} #create a blank dictionary\n",
    "\n",
    "for i in range(len(names_df)):\n",
    "    for col in source_cols:\n",
    "        name_to_consider = names_df.loc[i, col]\n",
    "        canonical_name = names_df.loc[i,\"IH & CSTK Handle\"]\n",
    "        if pd.isna(canonical_name):\n",
    "            canonical_name = name_to_consider\n",
    "        if not(pd.isna(name_to_consider)):\n",
    "            names_dict[name_to_consider] = canonical_name\n",
    "\n",
    "#### Did we catch them all? See if there's anything in the combned user sets of \"To\" and \"From\" that isn't a key in the names_dict dictionary. \n",
    "combined_users = set([]).union(set(data[\"From\"]),set(data[\"To\"]))\n",
    "names_uncaught = sorted([str(x) for x in combined_users if (not(x in names_dict.keys()) and not(pd.isna(x)))])\n",
    "\n",
    "# print(\"All told, there are {} names in our data set that lack canonical representations: \\n\".format(str(len(names_uncaught))))\n",
    "# print(\"We do not have canonical representations for the following names: \\n\")\n",
    "# for name in names_uncaught:\n",
    "#     print(str(name))\n",
    "\n",
    "def clean_name(name):\n",
    "    new_name = str(name)\n",
    "    new_name = new_name.lower()\n",
    "    new_name = re.sub('#\\d\\d\\d\\d','',new_name)\n",
    "    new_name = re.sub('[^A-Za-z0-9]+', '', new_name) #remove all non-alphanumeric characters\n",
    "    return new_name\n",
    "\n",
    "clean_name(\"zeptimusQ\")\n",
    "clean_name(\"ygg_anderson\")\n",
    "clean_name(\"AmwFund#0979\")\n",
    "clean_name(\"Caeser (PST)#0046\")\n",
    "\n",
    "cleaned_keys = []\n",
    "original_keys = list(names_dict.keys())\n",
    "for key in original_keys:\n",
    "    clean_key = clean_name(key)\n",
    "    cleaned_keys.append(clean_key)\n",
    "    if not(clean_key == key):\n",
    "        names_dict[clean_key] = names_dict[key]\n",
    "    \n",
    "new_pairs = {}\n",
    "\n",
    "for name in names_uncaught:\n",
    "    clean_version = clean_name(name) #clean the name \n",
    "    key_matches = [key for key in cleaned_keys if clean_version == key] #make a list of all keys with same cleaned name\n",
    "    if len(key_matches) > 0:\n",
    "        for match in key_matches:\n",
    "            if match in names_dict.keys():\n",
    "                right_name = names_dict[match]\n",
    "                new_pairs[name] = right_name\n",
    "                names_dict[name] = right_name\n",
    "                break\n",
    "                    \n",
    "# print(\"We were able to add the following names: \\n\")\n",
    "# for name in new_pairs.keys():\n",
    "#     print(str(name) + \"\\t ----> \\t\" + str(names_dict[name]))\n",
    "\n",
    "still_uncaught_names = sorted([str(x) for x in combined_users if (not(x in names_dict.keys()))])\n",
    "num_still_uncaught_names = str(len(still_uncaught_names))\n",
    "print(\"We are still missing {} names\".format(num_still_uncaught_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b1326cf-ddaf-4d9a-b150-f3bf21673356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 remaining users with no representation.\n",
      "These users are \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def total_appearances(name, data):\n",
    "    from_appearances = sum(data[\"From\"] == name)\n",
    "    to_appearances = sum(data[\"To\"] == name)\n",
    "    total = from_appearances + to_appearances\n",
    "    return total \n",
    "\n",
    "still_uncaught_appearances = [total_appearances(x, data) for x in still_uncaught_names]\n",
    "\n",
    "uncaught_df = pd.DataFrame({\"name\": still_uncaught_names, \"appearances\" : still_uncaught_appearances})\n",
    "\n",
    "for name in still_uncaught_names:\n",
    "    names_dict[name] = name\n",
    "\n",
    "last_remaining = [user for user in combined_users if(not(user in names_dict.keys()))]\n",
    "num_remaining = len(last_remaining)\n",
    "print(\"There are {} remaining users with no representation.\".format(num_remaining))\n",
    "print(\"These users are \\n\")\n",
    "\n",
    "for name in last_remaining:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc049a9-7bc0-4cca-91bd-f5934cfee6e5",
   "metadata": {},
   "source": [
    "Map the names in the dataframe to the resolved names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d512c86a-e41f-4912-b7f7-8e593a0de4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,\"To\"] = data.loc[:,\"To\"].map(names_dict)\n",
    "data.loc[:, \"From\"] = data.loc[:,\"From\"].map(names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df313c-2054-4e89-b9d8-e62ec05039d3",
   "metadata": {},
   "source": [
    "### Save Cleaned Praise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ea347c4-50df-4948-9fc6-4b7489ee3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('outputs/praise_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99181faf-d519-4e9c-b9a7-0fa0e87eb799",
   "metadata": {},
   "source": [
    "### Split Receivers and Quantifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f07a885-61f1-4fcf-8476-361472d9f606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receivers = data[(~data[['Institution', 'Date', 'Room']].isna().all(axis=1)) & (data['From'] != 'Quantifiers')]\n",
    "quantifiers = data[(data[['Institution', 'Date', 'Room']].isna().all(axis=1)) | (data['From'] == 'Quantifiers')]\n",
    "len(receivers) + len(quantifiers) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83fcc927-4ca1-4f0a-a3af-3450bf3928f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "receivers.to_csv('outputs/receivers.csv', index=False)\n",
    "quantifiers.to_csv('outputs/quantifiers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0942ca34-01ad-4814-831a-9e6c62c464c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#17 May 7', '#16 Apr 24', '#15 Apr 9', '#14 Mar 26', '#13 Mar 12',\n",
       "       '#12 Feb 26', '#11 Feb 12', '#10 Jan 29', '#9 Jan 15', '#8 Jan 1',\n",
       "       '#7 Dec 18', '#6 Dec 4', '#2 Oct 9', '#5 Nov 20', '#4 Nov 6',\n",
       "       '#3 Oct 23', '#1 Sept 24', '#0 Sept 7 (historic)', '#18 May 21',\n",
       "       '#19 Jun 4', '#20 Jun 18', '#21 July 1'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['period'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1579ee4-3cc0-459b-87ee-2636af494e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
